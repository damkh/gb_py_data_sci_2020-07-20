1) Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?
    Регуляризация в решающих деревья осуществляется алгоритмом  minimal cost-complexity pruning. Параметр регуляризации задается числом a. Данный параметр является коэффициентом количества терминальных узлов (листьев). Таким образом, увеличивая а - увеличивается количество листьев, что как бы усложняет дерево. Это и является штрафным слагаемым. То есть если количество листьев увеличивается, необходимо предпринимать действия по упрощению дерева - отсекать его части.
2) По какому принципу рассчитывается "важность признака (feature_importance)" в ансамблях деревьев?
    Мне удалось найти три метода вычисления важности признаков в алгоритмах ансамблей деревьев:
    - MDI (Mean Decrease in Impurity, Gini Importance). Чем больше, тем выше важность. Данный метод   уменьшает количество значений в признака и вычисляет точность модели после изменений. Чем сильнее уменьшение точности модели, тем выше важность признака. Может некорректно отображать важность, если признак содержит большое количество уникальных значений.
    - MDA (Mean Decrease in Accuracy, Permutation Importance). Данный метод перемешивает значения в признаке и измеряет точность модели. В отличие от MDI не имеет проблем с признаками с большим количеством уникальных значений.
    - Boruta. Данный метод так же как MDA перемешивает значения в признаках, но перемешанные данные добавляются в основной датасет
